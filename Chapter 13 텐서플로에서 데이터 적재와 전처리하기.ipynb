{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[참고](https://github.com/rickiepark/handson-ml2/blob/master/13_loading_and_preprocessing_data.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로는 데이터 API로 대규모 데이터셋을 처리할 수 있다. <br/>\n",
    "대용량 데이터를 읽는 것 뿐만 아니라 원-핫 인코딩, BoW 인코딩, **임베딩**(embedding) 등을 사용하여 인코딩되어야하는 <br/> \n",
    "전처리 과정을 처리하기 위해 사용자 정의 전처리 층을 만드는 방법도 있다.\n",
    "\n",
    "- TF 변환(tf.transform) <br/> \n",
    "    : 실행 속도를 높이기 위해 훈련 전에 전체 훈련 세트에 대해 실행하는 전처리 함수를 작성하고 텐서플로 함수로 변환에 상용 환경에 배포.\n",
    "- TF 데이터셋(TFDS) <br/>\n",
    "    : 각종 데이터셋을 다운로드할 수 있는 편리한 함수 제공. API로 조작할 수 있는 편리한 데이터셋 객체도 제공.\n",
    "    \n",
    "# 13.1 데이터 API\n",
    "- 데이터셋(dataset) : 연속된 데이터 샘플."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int32>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리에서 전체 데이터셋 생성\n",
    "import tensorflow as tf\n",
    "\n",
    "X = tf.range(10)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X) # 텐서를 받아 데이터셋을 만든다.\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋의 아이템 순회\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1.1 연쇄 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.repeat(3).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`batch()` 메서드에서 `drop_remainder=True`로 호출하면 길이가 모자란 마지막 배치를 머리고 모든 배치를 동일한 크기로 맞춘다. <br/>\n",
    "데이터셋 메서드는 데이터셋을 바꾸지 않고 새로운 데이터셋을 만들기 때문에 새로운 데이터셋을 반환받아야 한다(`dataset=...` 이런 식으로)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아이템 변환 : map()\n",
    "dataset = dataset.map(lambda x: x*2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (None,), types: tf.int32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n",
      "tf.Tensor([16 18], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 전체 변환 : apply()\n",
    "?dataset.apply "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 필터링 : filter()\n",
    "dataset = dataset.filter(lambda x: x<10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋에 있는 몇 개의 아이템만 볼 때 : take()\n",
    "for item in dataset.take(3) :\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1.2 데이터 셔플링\n",
    "`shuffle()` 메서드 :\n",
    "1. 원본 데이터셋의 처음 아이템을 `buffer_size` 갯수만큼 추출하여 버퍼에 채운다.\n",
    "2. 새로운 아이템이 요청되면 이 버퍼에서 랜덤하게 하나를 꺼내 반환.\n",
    "3. 원본 데이터셋에서 새로운 아이템을 추출하여 비워진 버퍼를 채운다.\n",
    "4. 원본 데이터셋의 모든 아이템이 사용될 때까지 반복.\n",
    "5. 버퍼가 비워지 때까지 랜덤하게 아이템을 반환.\n",
    "\n",
    "프로그램을 실행할 때마다 셔플링되는 순서를 동일하게 만드려면 랜덤 시드 부여."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 3 0 4 2 5 6], shape=(7,), dtype=int64)\n",
      "tf.Tensor([8 7 1 0 3 2 5], shape=(7,), dtype=int64)\n",
      "tf.Tensor([4 6 9 8 9 7 0], shape=(7,), dtype=int64)\n",
      "tf.Tensor([3 1 4 5 2 8 7], shape=(7,), dtype=int64)\n",
      "tf.Tensor([6 9], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "dataset = tf.data.Dataset.range(10).repeat(3)\n",
    "dataset = dataset.shuffle(buffer_size=3, seed=42).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "셔플된 데이터셋에 `repeat()` 메서드 호출하면 반복마다 새로운 순서를 생성하는데, <br/> \n",
    "반복마다 동일한 순서를 사용해야 한다면 `shuffle()` 메서드에 `reshuffle_each_iteration=False`를 지정하면 된다.\n",
    "\n",
    "대규모 데이터셋을 셔플링하는 방법\n",
    "1. 원본 데이터 자체를 섞는 것. 일반적으로 원본 데이터를 섞어도 에포크마다 한 번 더 섞는다.\n",
    "2. 원본 데이터를 여러 파일로 나눈 다음 훈련하는 동안 무작위로 읽는 것. 여기에 `shuffle()` 메서드를 사용해 셔플링 버퍼를 추가할 수 있음.\n",
    "\n",
    "### 여러 파일에서 한 줄씩 번갈아 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/rickiepark/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = load_housing_data()\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 캘리포니아 주택 데이터셋을 여러 개의 CSV로 나누기\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_mean = scaler.mean_\n",
    "X_std = scaler.scale_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메모리에 맞지 않는 매우 큰 데이터셋인 경우 일반적으로 먼저 여러 개의 파일로 나누고 텐서플로에서 이 파일들을 병렬로 읽게 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주택 데이터셋을 20개의 CSV 파일로 나누기\n",
    "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
    "    housing_dir = os.path.join(\"datasets\", \"housing\")\n",
    "    os.makedirs(housing_dir, exist_ok=True)\n",
    "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
    "\n",
    "    filepaths = []\n",
    "    m = len(data)\n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        filepaths.append(part_csv)\n",
    "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
    "            if header is not None:\n",
    "                f.write(header)\n",
    "                f.write(\"\\n\")\n",
    "            for row_idx in row_indices:\n",
    "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                f.write(\"\\n\")\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "train_data = np.c_[X_train, y_train]\n",
    "valid_data = np.c_[X_valid, y_valid]\n",
    "test_data = np.c_[X_test, y_test]\n",
    "header_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
    "header = \",\".join(header_cols)\n",
    "\n",
    "train_filepaths = save_to_multiple_csv_files(train_data, \"train\", header, n_parts=20)\n",
    "valid_filepaths = save_to_multiple_csv_files(valid_data, \"valid\", header, n_parts=10)\n",
    "test_filepaths = save_to_multiple_csv_files(test_data, \"test\", header, n_parts=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5214</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.049945</td>\n",
       "      <td>1.106548</td>\n",
       "      <td>1447.0</td>\n",
       "      <td>1.605993</td>\n",
       "      <td>37.63</td>\n",
       "      <td>-122.43</td>\n",
       "      <td>1.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.3275</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.490060</td>\n",
       "      <td>0.991054</td>\n",
       "      <td>3464.0</td>\n",
       "      <td>3.443340</td>\n",
       "      <td>33.69</td>\n",
       "      <td>-117.39</td>\n",
       "      <td>1.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.1000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.542373</td>\n",
       "      <td>1.591525</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>2.250847</td>\n",
       "      <td>38.44</td>\n",
       "      <td>-122.98</td>\n",
       "      <td>1.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.1736</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.289003</td>\n",
       "      <td>0.997442</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>2.695652</td>\n",
       "      <td>33.55</td>\n",
       "      <td>-117.70</td>\n",
       "      <td>2.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0549</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.312457</td>\n",
       "      <td>1.085092</td>\n",
       "      <td>3297.0</td>\n",
       "      <td>2.244384</td>\n",
       "      <td>33.93</td>\n",
       "      <td>-116.93</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  3.5214      15.0  3.049945   1.106548      1447.0  1.605993     37.63   \n",
       "1  5.3275       5.0  6.490060   0.991054      3464.0  3.443340     33.69   \n",
       "2  3.1000      29.0  7.542373   1.591525      1328.0  2.250847     38.44   \n",
       "3  7.1736      12.0  6.289003   0.997442      1054.0  2.695652     33.55   \n",
       "4  2.0549      13.0  5.312457   1.085092      3297.0  2.244384     33.93   \n",
       "\n",
       "   Longitude  MedianHouseValue  \n",
       "0    -122.43             1.442  \n",
       "1    -117.39             1.687  \n",
       "2    -122.98             1.621  \n",
       "3    -117.70             2.621  \n",
       "4    -116.93             0.956  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CSV 파일 중에서 몇 줄만 출력해보자.\n",
    "import pandas as pd\n",
    "\n",
    "pd.read_csv(train_filepaths[0]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedianHouseValue\n",
      "3.5214,15.0,3.0499445061043287,1.106548279689234,1447.0,1.6059933407325193,37.63,-122.43,1.442\n",
      "5.3275,5.0,6.490059642147117,0.9910536779324056,3464.0,3.4433399602385686,33.69,-117.39,1.687\n",
      "3.1,29.0,7.5423728813559325,1.5915254237288134,1328.0,2.2508474576271187,38.44,-122.98,1.621\n",
      "7.1736,12.0,6.289002557544757,0.9974424552429667,1054.0,2.6956521739130435,33.55,-117.7,2.621\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 파일로 읽으면\n",
    "with open(train_filepaths[0]) as f:\n",
    "    for i in range(5):\n",
    "        print(f.readline(), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets\\\\housing\\\\my_train_00.csv',\n",
       " 'datasets\\\\housing\\\\my_train_01.csv',\n",
       " 'datasets\\\\housing\\\\my_train_02.csv',\n",
       " 'datasets\\\\housing\\\\my_train_03.csv',\n",
       " 'datasets\\\\housing\\\\my_train_04.csv',\n",
       " 'datasets\\\\housing\\\\my_train_05.csv',\n",
       " 'datasets\\\\housing\\\\my_train_06.csv',\n",
       " 'datasets\\\\housing\\\\my_train_07.csv',\n",
       " 'datasets\\\\housing\\\\my_train_08.csv',\n",
       " 'datasets\\\\housing\\\\my_train_09.csv',\n",
       " 'datasets\\\\housing\\\\my_train_10.csv',\n",
       " 'datasets\\\\housing\\\\my_train_11.csv',\n",
       " 'datasets\\\\housing\\\\my_train_12.csv',\n",
       " 'datasets\\\\housing\\\\my_train_13.csv',\n",
       " 'datasets\\\\housing\\\\my_train_14.csv',\n",
       " 'datasets\\\\housing\\\\my_train_15.csv',\n",
       " 'datasets\\\\housing\\\\my_train_16.csv',\n",
       " 'datasets\\\\housing\\\\my_train_17.csv',\n",
       " 'datasets\\\\housing\\\\my_train_18.csv',\n",
       " 'datasets\\\\housing\\\\my_train_19.csv']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일 훈련 경로를 담은 리스트\n",
    "train_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 경로가 담긴 데이터셋 만들기\n",
    "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42) # list_files() : 파일 경로를 섞은 데이터셋을 반환함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 번에 다섯 개의 파일을 한 줄씩 번갈아 읽기\n",
    "n_readers = 5\n",
    "dataset = filepath_dataset.interleave( # filepath_dataset에 있는 다섯 개의 파일 경로에서 데이터를 읽는 데이터셋을 만든다.\n",
    "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1), # 각 파일의 첫 번째 줄은 열 이름이라 skip(1)로 건너뜀.\n",
    "    cycle_length=n_readers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`interleave()` 메서드가 잘 작동하려면 파일의 길이가 동일한 것이 좋음. <br/>\n",
    "기본적으로 병렬화를 사용하지 않으므로 각 파일에서 한 번에 한 줄씩 순서대로 읽는다. <br/>\n",
    "병렬로 읽고 싶다면 `num_parallel_calls` 매개변수에 원하는 스레드 갯수를 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'4.7361,7.0,7.464968152866242,1.1178343949044587,846.0,2.694267515923567,34.49,-117.27,1.745'\n",
      "b'3.6641,17.0,5.577142857142857,1.1542857142857144,511.0,2.92,40.85,-121.07,0.808'\n",
      "b'4.5909,16.0,5.475877192982456,1.0964912280701755,1357.0,2.9758771929824563,33.63,-117.71,2.418'\n",
      "b'3.6875,44.0,4.524475524475524,0.993006993006993,457.0,3.195804195804196,34.04,-118.15,1.625'\n",
      "b'2.3,25.0,5.828178694158075,0.9587628865979382,909.0,3.1237113402061856,36.25,-119.4,1.328'\n"
     ]
    }
   ],
   "source": [
    "# 지금까지의 데이터셋 확인\n",
    "for line in dataset.take(5) :\n",
    "    print(line.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잘 나오긴 했는데 바이트 스트링이라 파싱하고 스케일을 조절해줘야 한다.\n",
    "\n",
    "## 13.1.3 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리를 수행하기 위한 간단한 함수\n",
    "n_inputs = 8\n",
    "\n",
    "def preprocess(line): # CSV 한 라인을 받아 파싱한다. \n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs) # 파싱할 라인과 파일의 각 열에 대한 기본값 두 개의 매개변수를 받는다. \n",
    "    x = tf.stack(fields[:-1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    return (x - X_mean) / X_std, y # 스케일 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`decode_csv()` 함수는 열마다 한 개씩 스칼라 텐서의 리스트를 반환해 모든 텐서를 쌓아 1D 배열을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([ 0.4422319 , -1.7106786 ,  0.78773797,  0.03910041, -0.5277444 ,\n",
       "        -0.11205271, -0.541763  ,  1.156645  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.745], dtype=float32)>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전처리 함수 테스트\n",
    "preprocess(b'4.7361,7.0,7.464968152866242,1.1178343949044587,846.0,2.694267515923567,34.49,-117.27,1.745')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1.4 데이터 적재와 전처리를 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일에서 캘리포니아 주택 데이터셋을 효율적으로 적재하고 전처리, 셔플링, 반복, 배치를 적용한 데이터셋을 만들어 반환하는 함수\n",
    "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,\n",
    "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
    "                       n_parse_threads=5, batch_size=32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1.5 프리패치\n",
    "`prefetch(1)`를 호출하면 데이터셋은 항상 한 배치가 미리 준비되도록 한다. 즉, 알고리즘이 작업을 하는 동안 다음 배치를 준비한다. <br/>\n",
    "이렇게 하면 훈련 속도가 더 빨라질 것이다. \n",
    "\n",
    "GPU 카드를 구입할 때 초당 RAM에서 입출력할 수 있는 데이터의 수치인 **메모리 대역폭**(memory bandwidth)이 중요하다.\n",
    "\n",
    "`tf.data.experimental` 패키지에 실험적인 기능들이 있는데, 이 중 많은 기능이 향후 릴리스에 핵심 API가 될 가능성이 높다.\n",
    "\n",
    "## 13.1.6 tf.keras와 데이터셋 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 세트로 사용할 데이터셋 만들기\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "train_set = csv_reader_dataset(train_filepaths, repeat=None)\n",
    "valid_set = csv_reader_dataset(valid_filepaths)\n",
    "test_set = csv_reader_dataset(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "362/362 [==============================] - 2s 4ms/step - loss: 2.0699 - val_loss: 21.6364\n",
      "Epoch 2/10\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 1.0607 - val_loss: 0.7100\n",
      "Epoch 3/10\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.6137 - val_loss: 0.6093\n",
      "Epoch 4/10\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.6020 - val_loss: 0.5711\n",
      "Epoch 5/10\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.5825 - val_loss: 0.6348\n",
      "Epoch 6/10\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.5780 - val_loss: 0.6665\n",
      "Epoch 7/10\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.5234 - val_loss: 0.5160\n",
      "Epoch 8/10\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.5422 - val_loss: 0.4933\n",
      "Epoch 9/10\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.4903 - val_loss: 0.4706\n",
      "Epoch 10/10\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.4738 - val_loss: 0.4676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dd35e2a850>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(train_set, steps_per_epoch=len(X_train) // batch_size, epochs=10,\n",
    "          validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 704us/step - loss: 0.4788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4787513315677643"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set, steps=len(X_test) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.772925 ],\n",
       "       [1.4905939],\n",
       "       [2.510351 ],\n",
       "       ...,\n",
       "       [1.8501378],\n",
       "       [1.247444 ],\n",
       "       [2.8345075]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_set = test_set.map(lambda X, y: X) # we could instead just pass test_set, Keras would ignore the labels\n",
    "X_new = X_test\n",
    "model.predict(new_set, steps=len(X_new) // batch_size) # 새로운 샘플이 들어있는 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step 1810/1810"
     ]
    }
   ],
   "source": [
    "# 자신만의 훈련 반복을 만들고 싶으면 그냥 훈련 세트를 반복하면 됨.\n",
    "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps_per_epoch = len(X_train) // batch_size\n",
    "total_steps = n_epochs * n_steps_per_epoch\n",
    "global_step = 0\n",
    "\n",
    "for X_batch, y_batch in train_set.take(total_steps): \n",
    "    # 경사 하강법 수행\n",
    "    global_step += 1\n",
    "    print(\"\\rGlobal step {}/{}\".format(global_step, total_steps), end=\"\")\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X_batch)\n",
    "        main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "        loss = tf.add_n([main_loss] + model.losses)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 훈련 반복을 수행하는 텐서플로 함수를 만들 수도 있음.\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "@tf.function\n",
    "def train(model, n_epochs, batch_size=32,\n",
    "          n_readers=5, n_read_threads=5, shuffle_buffer_size=10000, n_parse_threads=5):\n",
    "    train_set = csv_reader_dataset(train_filepaths, repeat=n_epochs, n_readers=n_readers,\n",
    "                       n_read_threads=n_read_threads, shuffle_buffer_size=shuffle_buffer_size,\n",
    "                       n_parse_threads=n_parse_threads, batch_size=batch_size)\n",
    "    for X_batch, y_batch in train_set:\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "train(model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "● apply()              Applies a transformation function to this dataset.\n",
      "● as_numpy_iterator()  Returns an iterator which converts all elements of the dataset to numpy.\n",
      "● batch()              Combines consecutive elements of this dataset into batches.\n",
      "● cache()              Caches the elements in this dataset.\n",
      "● cardinality()        Returns the cardinality of the dataset, if known.\n",
      "● concatenate()        Creates a `Dataset` by concatenating the given dataset with this dataset.\n",
      "● element_spec()       The type specification of an element of this dataset.\n",
      "● enumerate()          Enumerates the elements of this dataset.\n",
      "● filter()             Filters this dataset according to `predicate`.\n",
      "● flat_map()           Maps `map_func` across this dataset and flattens the result.\n",
      "● from_generator()     Creates a `Dataset` whose elements are generated by `generator`. (deprecated arguments)\n",
      "● from_tensor_slices() Creates a `Dataset` whose elements are slices of the given tensors.\n",
      "● from_tensors()       Creates a `Dataset` with a single element, comprising the given tensors.\n",
      "● interleave()         Maps `map_func` across this dataset, and interleaves the results.\n",
      "● list_files()         A dataset of all files matching one or more glob patterns.\n",
      "● map()                Maps `map_func` across the elements of this dataset.\n",
      "● options()            Returns the options for this dataset and its inputs.\n",
      "● padded_batch()       Combines consecutive elements of this dataset into padded batches.\n",
      "● prefetch()           Creates a `Dataset` that prefetches elements from this dataset.\n",
      "● range()              Creates a `Dataset` of a step-separated range of values.\n",
      "● reduce()             Reduces the input dataset to a single element.\n",
      "● repeat()             Repeats this dataset so each original value is seen `count` times.\n",
      "● shard()              Creates a `Dataset` that includes only 1/`num_shards` of this dataset.\n",
      "● shuffle()            Randomly shuffles the elements of this dataset.\n",
      "● skip()               Creates a `Dataset` that skips `count` elements from this dataset.\n",
      "● take()               Creates a `Dataset` with at most `count` elements from this dataset.\n",
      "● unbatch()            Splits elements of a dataset into multiple elements.\n",
      "● window()             Combines (nests of) input elements into a dataset of (nests of) windows.\n",
      "● with_options()       Returns a new `tf.data.Dataset` with the given options set.\n",
      "● zip()                Creates a `Dataset` by zipping together the given datasets.\n"
     ]
    }
   ],
   "source": [
    "# Dataset 클래스에 있는 메서드의 간략한 설명\n",
    "for m in dir(tf.data.Dataset):\n",
    "    if not (m.startswith(\"_\") or m.endswith(\"_\")):\n",
    "        func = getattr(tf.data.Dataset, m)\n",
    "        if hasattr(func, \"__doc__\"):\n",
    "            print(\"● {:21s}{}\".format(m + \"()\", func.__doc__.split(\"\\n\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV 파일이나 어떤 특정 포맷을 선호한다면 `TFRecord`를 사용할 필요는 없음. <br/>\n",
    "`TFRecord`는 훈련 과정에서 데이터를 적재하고 전처리하는 데 병목이 생기는 경우에 유용.\n",
    "\n",
    "# 13.2 TFRecord 포맷\n",
    "TFRecord : 크기가 다른 연속된 이진 레코드를 저장하는 단순한 이진 포맷. <br/>\n",
    "각 레코드는 레코드 길이, 길이가 올바른지 체크하는 CRC 체크섬(checksum), 실제 데이터, 데이터를 위한 CRC 체크섬으로 구성됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFRecord 만들기\n",
    "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
    "    f.write(b\"This is the first record\")\n",
    "    f.write(b\"And this is the second record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
      "tf.Tensor(b'And this is the second record', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# 하나 이상의 TFRecord 읽기\n",
    "filepaths = [\"my_data.tfrecord\"]\n",
    "dataset = tf.data.TFRecordDataset(filepaths)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적으로 `TFRecordDataset`은 파일을 하나씩 차례로 읽지만 `num_parallel_reads`를 지정하여 여러 파일에서 번갈아 읽을 수 있음.\n",
    "\n",
    "## 13.2.1 압축된 TFRecord 파일\n",
    "특별히 네트워크를 통해 읽어야 하는 경우 TFRecord 파일을 압축할 필요가 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 압축된 TFRecord 파일 만들기 : options\n",
    "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
    "with tf.io.TFRecordWriter(\"my_compressed.tfrecord\", options) as f:\n",
    "    f.write(b\"This is the first record\")\n",
    "    f.write(b\"And this is the second record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
      "tf.Tensor(b'And this is the second record', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# 압축된 TFRecord 파일 읽기\n",
    "dataset = tf.data.TFRecordDataset([\"my_compressed.tfrecord\"],\n",
    "                                  compression_type=\"GZIP\") # 압축 형식을 지정해야 함.\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.2.2 프로토콜 버퍼 개요\n",
    "- 프로토콜 버퍼(protocol buffer, protobuf) : 이식성과 확장성이 좋고 효율적인 이진 포맷. TFRecord는 직렬화된 프로토콜 버퍼를 담고 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-44-af0b100d0e5c>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-44-af0b100d0e5c>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    message Person {\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 프로토콜 버퍼 정의\n",
    "%%writefile person.proto\n",
    "syntax = \"proto3\";\n",
    "message Person {\n",
    "  string name = 1;\n",
    "  int32 id = 2;\n",
    "  repeated string email = 3;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!protoc person.proto --python_out=. --descriptor_set_out=person.desc --include_imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from person_pb2 import Person\n",
    "\n",
    "person = Person(name=\"Al\", id=123, email=[\"a@b.com\"])  # Person 생성\n",
    "print(person)  # Person 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person.name  # 필드 읽기\n",
    "person.name = \"Alice\"  # 필드 수정\n",
    "person.name = \"Alice\"  # 필드 수정\n",
    "person.name = \"Alice\"  # 필드 수정\n",
    "\n",
    "s = person.SerializeToString()  # 바이트 문자열로 직렬화\n",
    "s\n",
    "\n",
    "person2 = Person()  # 새로운 Person 생성\n",
    "person2.ParseFromString(s)  # 바이트 문자열 파싱 (27 바이트)\n",
    "\n",
    "person == person2  # 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.2.3 텐서플로 프로토콜 버퍼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "프로토콜 버퍼의 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    syntax = \"proto3\";\n",
    "\n",
    "    message BytesList { repeated bytes value = 1; }\n",
    "    message FloatList { repeated float value = 1 [packed = true]; }\n",
    "    message Int64List { repeated int64 value = 1 [packed = true]; }\n",
    "    message Feature {\n",
    "        oneof kind {\n",
    "            BytesList bytes_list = 1;\n",
    "            FloatList float_list = 2;\n",
    "            Int64List int64_list = 3;\n",
    "        }\n",
    "    };\n",
    "    message Features { map<string, Feature> feature = 1; };\n",
    "    message Example { Features features = 1; };\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.train import BytesList, FloatList, Int64List\n",
    "from tensorflow.train import Feature, Features, Example\n",
    "\n",
    "person_example = Example(\n",
    "    features=Features(\n",
    "        feature={\n",
    "            \"name\": Feature(bytes_list=BytesList(value=[b\"Alice\"])),\n",
    "            \"id\": Feature(int64_list=Int64List(value=[123])),\n",
    "            \"emails\": Feature(bytes_list=BytesList(value=[b\"a@b.com\", b\"c@d.com\"]))\n",
    "        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_contacts.tfrecord\") as f:\n",
    "    f.write(person_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.2.3 Example 프로토콜 버퍼를 읽고 파싱하기\n",
    "`tf.data.TFRecordDataset`을 사용하고 `tf.io.parse_single_example()`을 사용하여 각 `Example`을 파싱."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설명 딕셔너리를 정의하고 TFRecordDataset을 순회하면서 데이터셋에 포함된 직렬화된 Example 프로토콜 퍼버를 파싱.\n",
    "feature_description = {\n",
    "    \"name\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "    \"id\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"emails\": tf.io.VarLenFeature(tf.string),\n",
    "}\n",
    "for serialized_example in tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]):\n",
    "    parsed_example = tf.io.parse_single_example(serialized_example,\n",
    "                                                feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(parsed_example[\"emails\"], default_value=b\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_example[\"emails\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 단위로 파싱\n",
    "dataset = tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]).batch(10)\n",
    "for serialized_examples in dataset:\n",
    "    parsed_examples = tf.io.parse_example(serialized_examples,\n",
    "                                          feature_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.2.4 SequenceExample 프로토콜 버퍼를 사용해 리스트의 리스트 다루기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "프로토콜 버퍼\n",
    "\n",
    "    syntax = \"proto3\";\n",
    "\n",
    "    message FeatureList { repeated Feature feature = 1; };\n",
    "    message FeatureLists { map<string, FeatureList> feature_list = 1; };\n",
    "    message SequenceExample {\n",
    "      Features context = 1;\n",
    "      FeatureLists feature_lists = 2;\n",
    "    };"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.train import FeatureList, FeatureLists, SequenceExample\n",
    "\n",
    "context = Features(feature={\n",
    "    \"author_id\": Feature(int64_list=Int64List(value=[123])),\n",
    "    \"title\": Feature(bytes_list=BytesList(value=[b\"A\", b\"desert\", b\"place\", b\".\"])),\n",
    "    \"pub_date\": Feature(int64_list=Int64List(value=[1623, 12, 25]))\n",
    "})\n",
    "\n",
    "content = [[\"When\", \"shall\", \"we\", \"three\", \"meet\", \"again\", \"?\"],\n",
    "           [\"In\", \"thunder\", \",\", \"lightning\", \",\", \"or\", \"in\", \"rain\", \"?\"]]\n",
    "comments = [[\"When\", \"the\", \"hurlyburly\", \"'s\", \"done\", \".\"],\n",
    "            [\"When\", \"the\", \"battle\", \"'s\", \"lost\", \"and\", \"won\", \".\"]]\n",
    "\n",
    "def words_to_feature(words):\n",
    "    return Feature(bytes_list=BytesList(value=[word.encode(\"utf-8\")\n",
    "                                               for word in words]))\n",
    "\n",
    "content_features = [words_to_feature(sentence) for sentence in content]\n",
    "comments_features = [words_to_feature(comment) for comment in comments]\n",
    "            \n",
    "sequence_example = SequenceExample(\n",
    "    context=context,\n",
    "    feature_lists=FeatureLists(feature_list={\n",
    "        \"content\": FeatureList(feature=content_features),\n",
    "        \"comments\": FeatureList(feature=comments_features)\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "context {\n",
       "  feature {\n",
       "    key: \"author_id\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 123\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"pub_date\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 1623\n",
       "        value: 12\n",
       "        value: 25\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"title\"\n",
       "    value {\n",
       "      bytes_list {\n",
       "        value: \"A\"\n",
       "        value: \"desert\"\n",
       "        value: \"place\"\n",
       "        value: \".\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature_lists {\n",
       "  feature_list {\n",
       "    key: \"comments\"\n",
       "    value {\n",
       "      feature {\n",
       "        bytes_list {\n",
       "          value: \"When\"\n",
       "          value: \"the\"\n",
       "          value: \"hurlyburly\"\n",
       "          value: \"\\'s\"\n",
       "          value: \"done\"\n",
       "          value: \".\"\n",
       "        }\n",
       "      }\n",
       "      feature {\n",
       "        bytes_list {\n",
       "          value: \"When\"\n",
       "          value: \"the\"\n",
       "          value: \"battle\"\n",
       "          value: \"\\'s\"\n",
       "          value: \"lost\"\n",
       "          value: \"and\"\n",
       "          value: \"won\"\n",
       "          value: \".\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature_list {\n",
       "    key: \"content\"\n",
       "    value {\n",
       "      feature {\n",
       "        bytes_list {\n",
       "          value: \"When\"\n",
       "          value: \"shall\"\n",
       "          value: \"we\"\n",
       "          value: \"three\"\n",
       "          value: \"meet\"\n",
       "          value: \"again\"\n",
       "          value: \"?\"\n",
       "        }\n",
       "      }\n",
       "      feature {\n",
       "        bytes_list {\n",
       "          value: \"In\"\n",
       "          value: \"thunder\"\n",
       "          value: \",\"\n",
       "          value: \"lightning\"\n",
       "          value: \",\"\n",
       "          value: \"or\"\n",
       "          value: \"in\"\n",
       "          value: \"rain\"\n",
       "          value: \"?\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_sequence_example = sequence_example.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_feature_descriptions = {\n",
    "    \"author_id\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"title\": tf.io.VarLenFeature(tf.string),\n",
    "    \"pub_date\": tf.io.FixedLenFeature([3], tf.int64, default_value=[0, 0, 0]),\n",
    "}\n",
    "sequence_feature_descriptions = {\n",
    "    \"content\": tf.io.VarLenFeature(tf.string),\n",
    "    \"comments\": tf.io.VarLenFeature(tf.string),\n",
    "}\n",
    "parsed_context, parsed_feature_lists = tf.io.parse_single_sequence_example(\n",
    "    serialized_sequence_example, context_feature_descriptions,\n",
    "    sequence_feature_descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.3 입력 특성 전처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "class Standardization(keras.layers.Layer):\n",
    "    def adapt(self, data_sample):\n",
    "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
    "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardization = Standardization(input_shape=[28, 28])\n",
    "\n",
    "sample_image_batches = train_set.take(100).map(lambda image, label: image)\n",
    "sample_images = np.concatenate(list(sample_image_batches.as_numpy_iterator()),\n",
    "                               axis=0).astype(np.float32)\n",
    "standardization.adapt(sample_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    standardization,\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\") # error\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set,\n",
    "          callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.3.1 원-핫 벡터를 사용해 범주형 특성 인코딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 캘리포니아 주택 데이터셋\n",
    "ocean_prox_vocab = ['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'] # 어휘 사전(vocabulary) 정의\n",
    "ocean_proximity = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"ocean_proximity\", ocean_prox_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean_proximity_one_hot = tf.feature_column.indicator_column(ocean_proximity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextVectorization(keras.layers.Layer):\n",
    "    def __init__(self, max_vocabulary_size=1000, n_oov_buckets=100, dtype=tf.string, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self.max_vocabulary_size = max_vocabulary_size\n",
    "        self.n_oov_buckets = n_oov_buckets\n",
    "\n",
    "    def adapt(self, data_sample):\n",
    "        self.vocab = get_vocabulary(data_sample, self.max_vocabulary_size)\n",
    "        words = tf.constant(self.vocab)\n",
    "        word_ids = tf.range(len(self.vocab), dtype=tf.int64)\n",
    "        vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
    "        self.table = tf.lookup.StaticVocabularyTable(vocab_init, self.n_oov_buckets)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        preprocessed_inputs = preprocess(inputs)\n",
    "        return self.table.lookup(preprocessed_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VocabularyListCategoricalColumn(key='ocean_proximity', vocabulary_list=('<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'), dtype=tf.string, default_value=-1, num_oov_buckets=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocean_proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = tf.range(len(ocean_prox_vocab), dtype=tf.int64)\n",
    "table_init = tf.lookup.KeyValueTensorInitializer(ocean_prox_vocab, indices)\n",
    "num_oov_buckets = 2\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1], dtype=int64)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 룩업 테이블을 사용해 몇 개의 범주 특성을 원-핫 벡터로 인코딩\n",
    "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
    "cat_indices = table.lookup(categories)\n",
    "cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 7), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_one_hot = tf.one_hot(cat_indices, depth=len(ocean_prox_vocab) + num_oov_buckets)\n",
    "cat_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.3.2 임베딩을 사용해 범주형 특성 인코딩하기\n",
    "표현 학습(representation learning) : 범주가 유용하게 표현되도록 임베딩이 훈련되는 학습.\n",
    "\n",
    "### 단어 임베딩(word embedding)\n",
    "ex) King-Man+Woman => Queen\n",
    "\n",
    "임베딩 행렬(embedding matrix) : 각 범주의 임베딩을 담은 행렬. 범주와 oov 버킷마다 하나의 행이 있고 임베딩 차원마다 하나의 열을 가진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 2\n",
    "embed_init = tf.random.uniform([len(ocean_prox_vocab) + num_oov_buckets, embedding_dim])\n",
    "embedding_matrix = tf.Variable(embed_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(7, 2) dtype=float32, numpy=\n",
       "array([[0.6645621 , 0.44100678],\n",
       "       [0.3528825 , 0.46448255],\n",
       "       [0.03366041, 0.68467236],\n",
       "       [0.74011743, 0.8724445 ],\n",
       "       [0.22632635, 0.22319686],\n",
       "       [0.3103881 , 0.7223358 ],\n",
       "       [0.13318717, 0.5480639 ]], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[0.74011743, 0.8724445 ],\n",
       "       [0.3103881 , 0.7223358 ],\n",
       "       [0.3528825 , 0.46448255],\n",
       "       [0.3528825 , 0.46448255]], dtype=float32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.embedding_lookup(embedding_matrix, cat_indices) # 임베딩 행렬에서 주어진 인덱스에 해당하는 행을 찾는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[ 0.04467482,  0.02493341],\n",
       "       [-0.02383961,  0.01973433],\n",
       "       [ 0.04309944, -0.0247813 ],\n",
       "       [ 0.04309944, -0.0247813 ]], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = keras.layers.Embedding(input_dim = len(ocean_prox_vocab) + num_oov_buckets,\n",
    "                                  output_dim = embedding_dim)\n",
    "\n",
    "embedding(cat_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_inputs = keras.layers.Input(shape=[8])\n",
    "categories = keras.layers.Input(shape=[], dtype=tf.string)\n",
    "cat_indices = keras.layers.Lambda(lambda cats: table.lookup(cats))(categories)\n",
    "cat_embed = keras.layers.Embedding(input_dim=6, output_dim=2)(cat_indices)\n",
    "encoded_inputs = keras.layers.concatenate([regular_inputs, cat_embed])\n",
    "outputs = keras.layers.Dense(1)(encoded_inputs)\n",
    "model = keras.models.Model(inputs=[regular_inputs, categories],\n",
    "                          outputs=[outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.3.3 케라스 전처리 층\n",
    "새로운 API는 사용하기 어렵고 직관적이지 않은 기존의 특성 열(feature column) API를 대체한다. <br/>\n",
    "이 API에 포함될 `keras.layers.Discretization` 층은 연속적인 데이터를 몇 개의 구간(bin)으로 나누고 각 구간을 원-핫 벡터로 인코딩한다. <br/>\n",
    "`PreprocessingStage` 클래스를 사용해 여러 전처리 층을 연결할 수 있는데, <br/>\n",
    "예를 들어 입력을 정규화하고 그 다음 이산화(discretization)하는 전처리 파이프라인을 만들 수 있다(사이킷런 파이프라인과 비슷)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=string, numpy=\n",
       "array([[b'it', b's', b'a', b'great', b'great', b'movie', b'i', b'loved',\n",
       "        b'it', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>'],\n",
       "       [b'it', b'was', b'terrible', b'run', b'away', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>']], dtype=object)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(X_batch, n_words=50):\n",
    "    shape = tf.shape(X_batch) * tf.constant([1, 0]) + tf.constant([0, n_words])\n",
    "    Z = tf.strings.substr(X_batch, 0, 300)\n",
    "    Z = tf.strings.lower(Z)\n",
    "    Z = tf.strings.regex_replace(Z, b\"<br\\\\s*/?>\", b\" \")\n",
    "    Z = tf.strings.regex_replace(Z, b\"[^a-z]\", b\" \")\n",
    "    Z = tf.strings.split(Z)\n",
    "    return Z.to_tensor(shape=shape, default_value=b\"<pad>\")\n",
    "\n",
    "X_example = tf.constant([\"It's a great, great movie! I loved it.\", \"It was terrible, run away!!!\"])\n",
    "preprocess(X_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<pad>',\n",
       " b'it',\n",
       " b'great',\n",
       " b's',\n",
       " b'a',\n",
       " b'movie',\n",
       " b'i',\n",
       " b'loved',\n",
       " b'was',\n",
       " b'terrible',\n",
       " b'run',\n",
       " b'away']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_vocabulary(data_sample, max_size=1000):\n",
    "    preprocessed_reviews = preprocess(data_sample).numpy()\n",
    "    counter = Counter()\n",
    "    for words in preprocessed_reviews:\n",
    "        for word in words:\n",
    "            if word != b\"<pad>\":\n",
    "                counter[word] += 1\n",
    "    return [b\"<pad>\"] + [word for word, count in counter.most_common(max_size)]\n",
    "\n",
    "get_vocabulary(X_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "normalization = keras.layers.LayerNormalization()\n",
    "discretization = keras.layers.experimental.preprocessing.Discretization([...])\n",
    "pipeline = keras.layers.experimental.preprocessing.PreprocessingLayer([normalization, discretization])\n",
    "pipeline.adapt(X_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BOW(bag of word) : 단어의 순서를 완전히 무시하고 빈도만 나타내는 텍스트 표현 방법.\n",
    "- TF-IDF(term frequency-inverse document frequency) : 단어 카운트는 자주 등장하는 단어의 중요도를 줄이는 방향으로 정규화되어야 하기 때문에 <br/>\n",
    "    전체 샘플 수를 단어가 등장하는 훈련 샘플 갯수로 나눈 로그를 계산한 후 단어 카운토와 곱하는 기법.\n",
    "    \n",
    "# 13.4 TF 변환\n",
    "- 훈련/서빙 왜곡(training/serving skew) : 전처리 과정을 바꿀 때마다 여러 과정에 걸쳐져 수정을 해야하고, 시간이 많이 걸릴 뿐만 아니라 에러를 만들기 쉽다. 훈련 전에 수행한 전처리 연산과 앱이나 브라우저에서 수행하는 전처리가 차이가 날 수 있음. 이 때문에 버그나 성능 감소로 이어질 수 있다.\n",
    "- TF 변환 : 텐서플로 모델 상품화를 위한 엔드-투-엔드(end-to-end) 플랫폼인 TFX(TensorFlow Extended)의 일부분."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Transform is not installed. Try running: pip3 install -U tensorflow-transform\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import tensorflow_transform as tft\n",
    "\n",
    "    def preprocess(inputs):  # inputs is a batch of input features\n",
    "        median_age = inputs[\"housing_median_age\"]\n",
    "        ocean_proximity = inputs[\"ocean_proximity\"]\n",
    "        standardized_age = tft.scale_to_z_score(median_age - tft.mean(median_age))\n",
    "        ocean_proximity_id = tft.compute_and_apply_vocabulary(ocean_proximity)\n",
    "        return {\n",
    "            \"standardized_median_age\": standardized_age,\n",
    "            \"ocean_proximity_id\": ocean_proximity_id\n",
    "        }\n",
    "except ImportError:\n",
    "    print(\"TF Transform is not installed. Try running: pip3 install -U tensorflow-transform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "애널라이저(analyzer) : 특성의 평균, 표준편차와 특성의 어휘 사전 같은 통계를 계산하는 컴포넌트\n",
    "\n",
    "# 13.5 텐서플로 데이터셋(TFDS) 프로젝트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "datasets = tfds.load(name=\"mnist\")\n",
    "mnist_train, mnist_test = datasets[\"train\"], datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABYCAYAAABWMiSwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAo0UlEQVR4nO2dWXBc132nv4vuRm/oHY1GY98JgKu4SJRp0ZSoiu2RK47HdkWesZNK5SkpP2Rq5mEeMg/JzMs8pCZTE8+4UpnVLrvKVtmKY7soKopMyqYkCgJBmcSOxo5e0QuARu995wE5RwBJUaQEoBvg/apYkgAIPPf0vb97/ruiqioaGhoaGvtDTaUXoKGhofEkoYmuhoaGxj6iia6GhobGPqKJroaGhsY+oomuhoaGxj6iia6GhobGPqKJroaGhsY+UnWiqyhKr6IoWUVRvl/ptVQaRVG+rSjKkKIoOUVR/k+l11MtKIriVhTlp4qipBVFmVcU5V9Vek2VRFGUjXv+lBRF+W+VXlelURSlQ1GUXyqKklAUJaQoyt8oiqKv9LqqTnSB7wDvVXoRVcIK8J+A/1XphVQZ3wHygA/418D/UBTlaGWXVDlUVa0Tf9jakwzw4wovqxr470AE8AOngM8Bf1rJBUGVia6iKC8DSeCNCi+lKlBV9Seqqr4KrFZ6LdWCoihW4KvAf1BVdUNV1V8DPwO+VdmVVQ1fY0to3qr0QqqATuBHqqpmVVUNAVeAir+cq0Z0FUWxA38J/NtKr0WjqukDSqqqTm772m2q4GGqEv4Q+H+qVt8P8F+BlxVFsSiK0gx8kS3hrShVI7rAfwT+p6qqi5VeiEZVUwek7vlaCrBVYC1VhaIobWyZ0P+30mupEq6x9TJeA5aAIeDVSi4IqkR0FUU5BbwI/JcKL0Wj+tkA7Pd8zQ6sV2At1cYfAL9WVXW20gupNIqi1ACvAT8BrEA94AL+cyXXBVUiusAloANYUBQlBPw74KuKogxXclEaVckkoFcUpXfb104Cdyu0nmriD9BOuQI30Ar8jaqqOVVVV4H/DfyLyi6rekT3b4FutiKMp4DvAr8APl+5JVUeRVH0iqKYAB2gUxTFVA0pL5VEVdU0W6eXv1QUxaooygXgy8D3KruyyqIoymeAZrSsBQBUVY0Bs8Cf/PNz5GTL3327ogujSkRXVdVNVVVD4g9bJmRWVdVopddWYf6crfSffw9885///c8ruqLq4E8BM1tR+h8Cf6Kq6pN+0v1D4Ceqqmpulg/5l8AXgCgwDRSBf1PRFQGKFuTU0NDQ2D+q4qSroaGh8aSgia6GhobGPqKJroaGhsY+oomuhoaGxj6iia6GhobGPvJxOZ9PSmqD8hg/q+3Jg9H25X60PbmfJ35PtJOuhoaGxj6iia6GhobGPqKJroaGhsY+oomuhoaGxj7yRDdP0TgcqKpKuVwmn89TLpcplUqoqoper6empgaDwYBer93qGtWBdidqHGhKpRLxeJxUKsWVK1dYWlpibm6OdDrN0aNH8fv9XLp0icHBQXQ6HTU1mnGnUVk00dU40JTLZdLpNPF4nA8++IDx8XHu3r3L2toa6+vrdHZ2MjAwQFdXF0ajkdra2kovWaPKEJZRqVSiXC4DoCgKer1+TywkTXQ1DjTFYpHFxUUWFxcZHx9nYmKCzc1NSqUS4+PjLC8vYzabCQQCnD9/nuPHj1NTU4OiPG4assZhI5/PUygU+O1vf0swGOS9994jEAhgNpsxGo184Qtf4Hd+53cwGAwYDIZd+3sPjOiKFpTlchlVVVEU5Yl/eMReCJ60/VBVlWKxyOrqKuFwmHA4TDT6YQvmSCRCNBrlzp075HI52tvb6e/v37MTjEb1oKoq97at3f7fqqqSz+fJZrPMz88zOTnJa6+9xvDwMHa7HYvFQnt7O88//7yMC+wWB+LOK5VKBAIB4vE4b7zxBrOzszz77LP09vbS1dVFc3NzpZe4rxSLRXK5HG+99RYrKysUi0UALl68yJEjR54I4c3lciwsLBAMBvnZz37G7OzsDsEVqKrK1NQU0WiUhoYGFEWht7eX7u7uCqxaY6/I5/Osr69TLBYpFAqk02lmZmbI5XKUSiVKpRKpVIp8Ps/a2hqlUgmHw0FNTQ1vvfUWgUCAxcWtmbjZbJZCocDm5iaFQmFXBRcOiOiWy2VCoRDz8/P8wz/8A0NDQxQKBcrlMi6X64kT3VKpRDab5YMPPmB0dJR8Pg9AT08PfX19AIdeeIvFIsFgkLm5OYaHhwkEAmSz2Qf+bDgcJhKJMDY2Rn19PU6n88CJ7oOGDRz2z/hRUVWVQqHA2toahUKBTCZDPB5nZGSEzc1N6UYIh8Nsbm4SDofJ5/O0t7djtVq5efMm8/Pz8veJ5ymfz+/w8+4WB0J0S6US09PTjI6Okkwmga0N2dzclKe8J4VMJsO1a9dYWFjg+vXrBAIByuUyNTU1zMzM0NfXh9PppK6urtJL3RNEwCOZTMrrj8Vi8gF52P83MTFBNpvF5/Nx/vz5fVz1p+POnTu89dZbpFIpIpEIbrebY8eO4fP5OHPmzBMVHBTpgdlslnQ6zcLCAkNDQySTSZaXl8nn82QyGTKZDKFQSB7OisUimUyGYrHIxsYGqqqyvr6OTqcjkUjs6zUcCNEtl8ssLS0xOTnJxsYGAIVCgWw2+8SJbj6fZ2hoiDt37jA8PEwwGATAYDCwvLxMLBbDaDQeatEtFAqsr68zPDzMzMwMyWRSnk4exvz8PKFQiMuXL+/DSneP2dlZXnnlFVZWVpiYmKCzs5Pf/d3fZWBggBMnTjxRortdQBOJBGNjY/zkJz8hGo0yNzcn3QLCMniQNSC+Fw6HK2ItVLXoqqpKOp0mlUoxNzfHzMwMer2epqYment7OX78OPX19ZVe5r5QLpdJJpNEo1HGx8e5c+eOfAEZDAaMRiNmsxmLxXKog0SJRII33nhD3g/hcJhCoSC/rygKTqeT2tpaUqnUDpeDCK4clLmAmUyGdDpNJBIhGAxKKy+ZTPLee+8Rj8fx+/24XC7a2tqk71Gn02Gz2eR9UC6XiUQibG5ukk6nyefzWCwWjEYj9fX1uFwuFEWpandFNpslk8kwPj7OrVu3iMfjhMNhlpeXmZmZYXNzk2w2S21tLS0tLej1eux2OyaTiaamJoxGIwaDgVwux7Vr1wiHww/8exRFkamFJpNJFtjsJlX9dArRTSQSLCwsMDMzQ1tbG263myNHjnD8+HGcTmell7kvCJM6HA4zNjbG3bsfDr/V6/XU1tZK0d1tx381EY/H+fnPf87s7CwzMzOk02ngwxNNTU0Nbreburo6stnsfX7eezM+qhVVVclkMqyurhKNRgmFQvJakskkQ0NDhMNhPB4PTU1NAJjNZhRFkRV4RqMR+DCtLhaLSfF1u93Y7XZqamqw2+3odLqqFl1xsr158ybf//73iUajLCws3PdzQmStVit+vx+n08nZs2ex2WxYrVbW1tYYGxv7SNEVv8NqtWI2m5880S0UCkxOTjI/P08ymURVVcxmMw6HA7vdjs1mO9QCs51CocD8/Dxzc3NkMhn5dUVRMJvNcj8O654I/524H0Kh0A7XkqIoWK1WrFYrly9fpq2tjTfeeINAIMDq6qr045XLZTKZDKlUCqPRiMlkquBVPRhxIh0aGuL69ev89re/JZvNSp+1uI5kMsnw8DDT09PMz8/vOOk6HI4dJ91QKMTGxoY86VqtVmpraxkbG6OtrY2BgQEGBgbQ6XRVZSmJasP333+f4eFhRkdHCYfDZDIZedBwu9243W66u7txuVwcOXIEs9mMzWbDbDbT0tJCTU2NfOGI+8ZgMOwQ1EKhgKqqOJ1O/H4/brcbo9G46/tRPbv7AAqFArdv32ZiYoJYLEa5XMZiseB2u3E6nTgcjkovcd/I5/NMTk4yPT3N5ubmju/V1dXhdDoP9Z6sr6/z/vvvMzU1xeTkJIlEYocfV6fTYbfb8Xq9fOUrX+Hs2bPk83lqampk8ET0ZUin08RiMZxOZ1WK7vr6OpFIhH/6p3/ir//6rx8YIBT5ydevXwceLZPh3hO+oih0d3fT3NzMyy+/THt7uzSpq4VwOMzs7CyvvvoqP/jBD+Q11NbWSvdIf38/vb29fOlLX8Lr9cpc7O17srGxQTAYlPcBcF++drlcplAo4PV66evrw+fz7cn9sS+7u7m5STKZJBaLMTMzg9PppL+/X55aP+qGKZfLrK+vs7q6Kt9Odrud+vr6qnxY9pJCocD09DRjY2M7TGqDwUBHRwddXV14PJ4Kr3L3SafThEIh5ubmuHHjBsvLy2QyGVm6qSgKdXV1WK1WnnvuOdrb2/H7/fKhNJlM6HQ64MMTYiqVIhgMUlNTU1V7ls/nyefzjI2NMTQ0xMTExA7BFZ+3+HchEsJPLZ6jB4mrQJjL23NXFUVhYmKC9957j46ODpl2WEmEj/b27du88847zMzMoKqqtGba29s5duwYHo+H9vZ2fD4fzc3N2Gy2B7pKdDodTqcTn89Hb28vBoOBuro69Ho9S0tLJJNJWVzU1dXFZz/7Wdra2vbk2vZFdJPJJJOTkwwPD/OjH/2I/v5+/uiP/oiGhgZ54Q+iXC5Lf1Yul5P+upaWFqxW634svWrIZrO899573L59e4fo6nQ6nnrqKZ5++ulDma8s/Jd3797llVdeYW1tjXw+L4VFr9fjcrlobGzkG9/4BsePH8fn86HX67FYLFitVim6Qmii0SiTk5MYjUY6OzsreXk7SKfTrK+vc/36db73ve/JwJlAr9djMpmkoJRKpR1BxEehtrYWg8EgX1zRaJRoNMqNGzfI5/Ncvny5KkQ3mUwSj8e5evUqP/zhD+XLx26309bWxosvvsgf//EfY7PZdgQCP+oAJwLwJpOJZ555hvb2djweD3q9ntdee43NzU1yuRw6nY4zZ87wjW98Y8+yQvZFdEXJbqFQYHV1lUgkQjgcxmAwPDDxWJTopdNpGUgQlSF+v5/Ozk5sNtt+LL0qKBaL5PN5crncDt+e8Gk1NjYeuj0plUrk83lisRijo6NMT0/L6iLYCpjV1tZSV1fH8ePHaW1tpbGxEbvdjsFgeGiwbGNjg1AoRHt7+35dziMRi8Vkld3a2hq5XA4Ap9NJU1MTLpeL1tZW9Ho9Op2ObDZLOBx+aH7ydkRmh9FoZGhoiEAgIL9XKBTI5XJVkYKpqqq0jkVubblcRlEU2trauHTpEseOHZPZCeKl+jBqamqoq6tDURSOHTtGc3PzjkBrLpdDVVXp066trX2k3/tJ2BfRFQ9IPp9neXkZo9HI5OQk5XKZp5566r6fL5fLrK2tEYvFCAQCTE9Py5PL0aNH+cxnPoPL5dqPpVccEfjZ3Nwkk8nIm0QE0BwOB4ODgzzzzDNVHX1+XPL5PMlkkkAgwJUrV4hEIvJ0Bh+mRTU2NvJ7v/d79Pb20tvbi9PpRFGUh+btRqNRRkdH6ejo2Ker+XhUVWV6epq3336bsbExYrGYfHG0t7fzwgsvMDAwwOXLl2X6UyqV4u7du4+Uowxbz2FzczMWi4W/+Iu/2CG6osqxGkQXtgJoi4uLrK+v73ipnD59mj/7sz/DYrFgs9ke+Z7X6XR4vV68Xi+tra3k83neeecdFhYWKJVKrK2tSStgtxvc3Mu+iK5Op5NRQOFXe1jqjjB7RNleqVTCZrNJ391hz0XdTj6fZ3Z2ltnZ2R3pTyJab7fbMRqNh6ZPrDCZQ6EQH3zwAXfv3iUej+9IeIetU357ezstLS00NzfT0NCA0Wh8pIcwm83el8NbSdLpNNlslqWlJaamplhdXd1xrQ6Hg97eXlpbW3E4HDIlTFEUWlpaHlkohf+7pqZG+j3F35NOp4lGo1LkKtk86d6T7nZEYYTBYHjs9Ymf1+v1lEolGaQT7jqv14vH49nzNNR9Ua7a2locDgcWi+WRfj6XyzE6OkogEGBtbQ1VVfF4PPh8Plk7f5hOdQ9jbW2NK1euyMorgU6no76+nubmZsxmc+UWuMvkcjmSySQ3b97kO9/5jszHLBaLO4Sorq6O559/nu7ubk6dOkVDQ8Mjm4OpVIqlpSVSqdSOAFQlUFWVUChEMBjkxo0bXLly5b6XQWtrK5///Oex2Wzy3lcUBZPJ9FgCoaoq0WiUVCp13/fC4TAbGxs8/fTTFAqFindiW11dZX5+nvX19R1fX1tbY3Z2lubmZtxu9yf+7AqFAu+++64Mzup0Ok6ePMmJEyf23ALal10VLfgetXGESAwXp1xFUbDZbDJv7kkRXNi6OZaXl1lcXJQ+PtgyFX0+H62trY/8MjsIJBIJJiYmCAQCRCIRUqnUDsHV6XSYTCYcDoc85ZrN5sfyv9XV1dHQ0FA1wVgREC0Wi9JnL+55h8OB1+vFYrFgMpl2WDSi0fajIrKBhKtmO0ajEbvdLgssKv2M1dXV4fF4MJvNO1624XCYW7dusby8TDAYxGQyyZJ3kZmh1+sxGAwyZ91sNst9E/nNiUSCWCxGIpGgXC5jMBhoamriyJEjuN3uPb22fRHdQqHAxsbGfR/0RyHSepLJJMViEZ1OR3t7O729vdjt9j1ebXWRTqd5++23mZyclGYQbN1g586d4+zZs/j9/gqucHcZHR3l7/7u71hYWGB+fv6+E67BYKClpYXu7m4uXLhAe3v7Y/eZ6Ozs5NKlS/T09FRcXBRFwWKx4HQ60ev15HI5KRq9vb2cO3eO06dP70rRS7lcZnx8XBYYbKexsZHBwUFaWlqora2t6L4oikJfXx8Oh4Ph4eEd33vnnXcYGRmR4trY2MjRo0cxmUxYLBZqa2tlzvrp06dxOp309vbK6rxCocDIyAjz8/OMjo4yPz+P1WrF7Xbzmc98hq9//et73stiX0Q3l8sRj8dlVdDDIsvibS+yHERKjNvtxu/3HypT+lFQVZVcLndf5N5gMOB2u2loaDgUOcuiofTq6irLy8usrq7KQZOAPH1ZrVZ6enro7u7G6XRisVgeyZ+9/Z7T6/WyIqsaEFkoLS0tHDt2TEbQBwcHOXLkCI2Njbs23y2Xy8k+sdvR6XTU1tbeV1RQCba/iFpaWujt7WV9fV26gzKZjMxRBmTGislkwmg0SgvBaDTicDjY3NyUz0gul2N8fJylpSU2NjYoFouyd8l+Xfu+iG44HObmzZvMzMw81MUg+gsEg0GuXbvG2NgY8Xgco9HIqVOneO6552hoaNiPJVctImvBZrPR29vLiRMnDoXoRiIRAoEAt27dYmRkRLbkEyiKIpuZfPvb36atrY3m5uaPdTc96CUvTM5qKZd2OBzYbDa+9a1vcfnyZWpra6mtrcXlcuHxeGQDlk8rCNtTMe/d22rD5XJhs9n46le/yvHjx/nNb37Db37zG5natr6+TiKRIB6P8/777+8I/NXU1FBTU4PZbJYnX+F+Eu6FbDZLMpmUbhyv18vGxgZzc3P4fL49dTHsueiKSGQwGCSRSMh+qKlUikQiQSgUwmw2yzdXNBplaWmJRCLBxsYGNTU1mEwmGUSoltPJXiNaGOZyuR2ZHqLcVTR1udfPd9AQophMJpmdnZV19feKgtlspqGhgZaWFvx+P16v96ERbHGf3euegK09NBgMe5aH+biIU6zH45HpSrW1tVgsll1p0Sl6x25sbEg/pogPbBeoaiqLFv7Z+vp6mc0SjUZlvrpIKRVTVERWFCD7S5fLZXK5nHSliKwpkXooUu1KpRK5XI5gMCjbx6ZSKVn9Jj6PXbu2XftND0DUus/NzfH666+TTCYplUqsrq5y48YNpqamWFpaQqfTybSZhYUF2cqxUCjg9/tpaGiQaUFPSqpYLpdjaWmJpaUlGVxRVRWDwcD58+fp6enB5/NVjXB8UsSL5d133+W73/0u0Wj0PleAwWCgq6uLb37zm3R0dNDW1ibLPR+ESDvb2NiQ0wTgQ4GxWq14PJ6qCkCKwgWReyoKinaDQqHAm2++yfT0ND//+c8ZGxtjbW0N+LBC7ciRI7z44otVM1FDfFZtbW34/X76+/v5/d//fSm6oj1AKBRibGxM9tcW4itOvhsbG7z77rusr6/LdDjxLAlCoRCRSIS//du/xWQyyZf6Zz/7WS5cuEBTU9OuZjTsqYKJLu5ra2vE43EZSCsUCjJqaLFYUBRFiu7i4uKOIgCn0ymjt58kN++gIk79sVhsh6ktggfNzc1Vcyr5NIgX89raGsvLy7KZz/acyrq6OlwuF52dnbS0tDy0CklYVuJkJ/x2QsREoY7NZpPBlWpBp9Pt6ktUtEbd2NiQrVFDoZA8/MCHbQzdbjc+n6/qAtXC1SIyTQqFAvl8no2NDemCEF/LZDJSTIWVk0gk0Ol0UmyLxaKs6BMuJjF1ROxLNpslkUjQ1NQkXViiU9luvAj3VHSXlpa4e/cuo6OjcmgcbPXGXFhYQK/Xy6oY8fYRpkI+n8dms3Hp0iUGBgZobGx8YgQXtvIUf/zjHzM7O0symZRvb4vFwrPPPsvZs2fxer2VXuanRpxKRd/ke0taHQ4Hp06d4vjx45w/fx6Xy/VQsSwWi9y8eZPZ2Vlu3rzJ6OiofIGLAFVbWxunT5+uOtHdbbLZLK+//jqzs7P89Kc/ZXp6mlQqJZvkAPT19TE4OMizzz7LsWPHqt59JwRT5P43NTXR39+/w70AW1k/ExMTLCwscPXqVelm0uv1NDc343Q6uXjxIn6/n8nJSaLRqBxumslkSCaT/OIXv+Cdd97hK1/5Cj6fT3bz+9TX8Kl/w0PY3NwkEonI6ZsiKrnddMrn89KcEn5M8eApiiL9eE9S1oLwOy0tLbG8vCz9b8LUdrlceL3eqn9AHoYY+Le+vk48Hr+vkY3AaDTi9XrlhIOP83GKJknLy8vE4/H7kutFp65HzXo4iIjnKJ1Os7i4yPT0NEtLSzvSxIR4eb1eOjo6ZPOpame760VkLGw/nYv5aQJxwi2Xy7LgQ9xPPT09sqLParWSzWYpl8uEw2Gy2SyRSIRkMkkkEiGbze7aS3pPRTeZTDI9PU0sFkOv1+P3+zl58qTcKL1eL4/4FouFWCzGD37wA2KxGLBlWoixPNVm9uwVhUKBZDJJKBRiamqK5eVlaRJ5PB4aGxvxeDw7mlQfRMLhMNFolCtXrvDaa6+xtLT0wFRCh8PByZMn6e7ufqTrFUNMb926dd/AQTFfS7QYdbvdh8JauJdsNsvIyAjLy8v88pe/lCc5gaIoNDc34/V6+fznP88Xv/jFPS8I2C9EH+LFxUWuXLlCLBZjZWWFUqlEW1sbHo+Hb37zm3R3d9PT04Pdbuepp54il8sxNTVFMBjkRz/6Ef/4j/8o3Q6izeRuFdPs6VMrKtFqa2ulz6i7u1vm4G3vaWk2m1lZWZGnNxExdDgcuFyuqknv2WuKxSJra2uyOEQ4/w0GA3a7XXZWOuj7sba2RigUYmJigvfff/++pi2iSktkLbhcro89mQpXRTweJxKJ7Kjggw8zJYRPsFoq0nYDYV7n83nW19dZXl5mfn6epaUlgsGg3F+xr6JzWWtrK52dnQf+1C8yEOLxONPT08zNzTE6OirbCBiNRjweDy0tLfT19dHX1ydz3L1e747ezNubaW13WezWmKc9Fd1jx47h9XpJp9Mkk0k5WkOk7IjGG+l0mqmpKXmBRqOR/v5+Wltbqa+v31HGd9hZXV3l6tWrTE1N7TC5LRYLFy9epKenp6oab38SVFXl5s2b/PKXv2RsbGxHAERgNBpxOp10dnbKrnIPO+kWi0Xm5uaIRCKMj48zPT39QNeCyPe1Wq2HxqdbLBZlaeuvfvUrVlZWuHbtGpFIhMXFRXkPKYoiUw1feuklLly4QH9/f0Wb23xaxMtmcnKSn/70pywuLvLrX/+atbU12TlscHAQv9/P1772NVpbW+nr68Nut9/nnotEIszOzsreFA6HA6fTSWtr664GrvdUdD0ezyMJRCKRYGpqSvpehK/J5/M9dl39QSeTyTA7O8v8/PyOiiyDwUBbWxtdXV2HImshEokwMTFBJBJ5YJes2tpa7HY7LpcLv9//0FOpyPFeXV0lGAwSj8cfGJQTARgxVeIw3FfCmlxfXycajXLnzh3m5+cZGRmR7hVxuhU9Zd1uNz09PZw8efKhk1uqGZFzK073kUiEoaEhVlZWmJqaIp/Py0ozkfJ16tQp2avk3s9eZL3E43HpExYNhUTxym4d/KrCKbixscHw8DCBQIBsNovBYKC5uVnObHqS2NzclPnL28VIVOWJB+Wg09bWxtNPPy2n2t6L2+3m7Nmz9PX1PVQcRUe6SCTClStXmJ+flz1S7+XEiRMMDAxw5swZGhoaDryLJpfLsbq6Sjgc5urVq6ysrPCrX/2KRCKxY46eXq+nu7sbj8fD5cuX6e3t5cyZMwfSbSca+YfDYWnZTE1NEQqFZOc4RVGor6/nmWeeoampiZdeekmmWT7IahZDAu7evcubb74ppwz39/fz3HPPMTg4uGvpYlAlopvP52UhgKiFFkf7gxws+iSIaQmrq6s7sjhEo5fW1tYKr3B3EFMQpqamHvh9q9Uq3Uuw07cmUFVV9qFdXFxkZGSEubk5mfgvENHupqYmOWXiMPhzhf86GAzKwFkgELhvnJNOp8Pn89HS0sLZs2c5efIkbrf7QGUECTeCKIwIh8NMTEwwOzvL0NCQrAcQhzabzUZ/fz/t7e2cPXsWj8fzkaXUojotFArJtDrY6q979OhRGhsbd9W9WRWKlslkmJmZYXFxkUKhIAfPdXd3H6gb49OwvdlLOByW5rHJZKKzs/NQ7YXoBetwOD7SkhFmcywW4+2336ZUKhGJRGSwo1gssry8LMeQiwCK8IMLdDodbW1tNDQ0cPHiRS5fvkxjY+N+XeqeUCwWSafTzM3N8corr7C8vMytW7dIpVI7rt1kMnHx4kWampp4/vnnaW1tpaurC7fbfWAsSOFyvH37Nh988AELCwtMTk7KirR0Ok0kEpEBV7vdTnd3N42NjVy+fFlODv+oZjaqqrK6uipfXsLqEr7co0eP7nqGS1WIbrFYlAPySqUSer2e+vp6fD7fgc5FfRzy+TzxeJx4PE4qlZKjog0GA62trbLl3mFBNJ152FBSUak2NTVFOp0mEAjIHgXZbJbR0VESiQR37twhnU7vSPqHD3saiKyZ/v5+jh8/fiB9mNsRohsKhbhx44Y0te/NADEajRw9epTBwUEuXbp0IK0kUUUWCAS4fv06d+/eZWhoCPgwMApbp1KbzUZzc7Ms3T1z5szHHlREX4p4PE4ymSSVSuFwOKirq5OjfXY74FpR0c3n89InJQZPdnZ20tzcTEdHhyz5fBIIhUL8/d//PVNTUztmgVmtVi5cuCBzCp8UwuEw165dw2g0YrVaZYQekA2SotGobFW4vZ5elIyLSsaLFy/S399Pf3//gRdc2JofduPGDcbHx5mbm5Plq9sLP86dO4ff7+dzn/scHR0dez6CZrdZXV1lY2ODW7duMTk5ycjICCMjI8TjcQD8fj9HjhzB7/czODgoq9NsNhttbW2yUc1HIUqkNzc3uXLlCrdu3WJiYgKAI0eOyLaaexHIr7joRqNR4vE4hUIBnU5HU1MT7e3tNDU1PVFtHGOxGNevXycYDMrGHbAlMCdPnqS3t7eqGrTsNYlE4r7ihu3cm2ImxFSkhNXV1XHs2DH6+/t58cUXOXbs2J6udz9JpVLcvn2b6elpgsGg7GkiqrTsdjvnzp2ju7ubp556Cr/ff6AyNVRVJZVKEYlEuHHjBm+++aacFCHwer089dRTHD9+nC996UuYzebHrqgT5b43btzg6tWrch/b29s5f/487e3te2JdVlR0RV7hzMwMGxsbbG5uMj8/T6FQ4NatW6yvr9PT03MgyhM/KcKMFjeAaPSuKIo85YnUu8MUVPR6vfT29tLS0oLX6yWTybCxsfGJfpfJZMJkMtHV1YXT6WRwcJD6+npOnDghu9QdBsLhMGNjY4yPj3Pjxg1isZgcIima+Jw5c4ampibOnz8vB1kexDzclZUVJicnmZ2dZXl5+b57w2w24/V6sVqtsiHU9skqH0WpVCIWi8mMKfH35HI52UK2t7eXs2fP0tTUtCfXVnHRvXbtGktLSzLymMvlyGQyDA8Pk06nZaOJw4rIMxSiu7a2JnOVRQcoj8eD2+0+dKJrNptpa2vD6/VKc/JxEb1g7XY7p06dkuPK29raqK+vP1TWQSQS4dq1a0xMTHDz5k1yuZwsETcajbhcLi5cuEBXVxfPPvvsgS2iUVWVYDDI2NgYc3NzhEIhgB3Ti00mk/x8RbluOp3+2KqxQqHA+Pg40WiUV199lUAgQCKRIJvNyorPnp4eTp8+vWfXVxVPsXgLGwwG2cqxp6eHrq6uQxOx/yjy+TyJREKeckWXNb1ej8/nk6PFxcjsw4JwAZw+fZpiscjS0hKBQECOxRZ9du/FZDLR3t6O2WymsbERq9WK3++nrq6OEydO4PF4aG5uliNcDgPbiz8mJiZYXFykWCxKP7bRaKSrq4u2tjZOnDhBa2vrgX5uRG+Io0ePMjMzQyAQ2NHuFWBxcZHXX38dl8vFyMiIDC5+3PBb0dAmnU6zsrLC5uYmHo9HWge9vb0MDAzs6fVVXHS357/pdDr50AwMDNDX13co8ikfRi6XIxaLyY5YwkQSlTRNTU0YjcZDVwYtXALPPfccZ8+eZWJigpGREYaGhmQq0INEV4irz+fj3LlzuFwu+vv7sdvth3ayiJgbKCbhJpPJHdWKFouFY8eO0d3dzTPPPIPP56vwij8diqLQ0dGB3W6XrWFXV1d3iG4gEGB2dhaj0YjFYpEn3e1FMQ+bKgIfdlrr7u6mqamJr3/963zuc5/b8+B9RUW3WCzK9CidTofNZuO5556js7MTr9d74EfRPArpdJqFhQUikciOG8ZsNtPb20tXV9ehFBKBXq/HZDLh8/kYHByU7hQxqPJec9FqtTIwMIDdbpeTgEW+70EKFj0Oa2trLCwssLS0xPr6ugz4iNaGHo+H48eP09HRcWiyfcRh6+mnn8ZgMMjpDul0mrW1NTmmR2RsiAPL9vtFWIx1dXU7RrKLAZyNjY3U1dUxMDCAz+ejvb19X8rDK569EIlEWF1dRafT0dDQwMsvvyxH0RyWhiQPI5lMcvfuXebm5naYRnV1dZw7d46Ojo4DbSp+HGImWFdXF52dnTsGST7IP7c9N/Pefx5WotEoQ0NDjI6OEovFZD6uXq/H7XbT0dHBCy+8QFNT06GxDB0OBw6Hgy9/+cu89NJLzM/PMz8/z8rKCnNzczK3tlAoUCwWCQaDrKys3Pd7RP9cMUXaarXKKdLnzp2jsbFRNpHafm/tJRUVXVF1BFvmtJhyW1dXd2hPLfdis9no7u4mlUphNpvlh261WqVP9zAF0B7Gft30Bw29Xo/FYpGHEPEyslqtHDlyhJ6eHhwOx6FszC4GVDqdTorFIhaLBYfDIbNdRI/kZDJJZ2fnfc2TRFtZk8lEY2OjzAgyGo20tbXhdDr3vYthxUVXpHtYrVYcDoeM1D8p+Hw+Ll26BGyVHqbTadmC78iRIzQ3Nx9q94LGxyNcCDabbcfX3W43ly9fprOzU5rKhw3RaKaxsRGfz/eRltC943q2I17m91pGIpVuv1/0FRVdl8vFpUuXSKfTmM3mQ2UePSqigXtLSwsvvPCC9FO1t7dLH5R2+nuyEY22PR4PTqeTTCZDLpeT/Qbq6+sPvWV4mKygiopuX18ff/VXfyWLAUTO5ZOEcPQ//fTTnDhxQr69RZ7uYTMXNR4fl8uF1WolGAzS09NDPB4nFArhdrvp7+/H7/cfmvS4J4GKiq5OpzuUJtHjoiiKFF8NjXsR5b0NDQ2cOXOG9fV1YrEYPT09uFwuOexV42CgfEwFx+4MBap+HueO1fbkwWj7cj+7uif5fJ7NzU3pv9Tr9Vit1l1tsP0J0Z6f+/nIPdFEdwvtprkfTXQfjHav3I+2J/fzkXuiOQw1NDQ09hFNdDU0NDT2kY9zL2hoaGho7CLaSVdDQ0NjH9FEV0NDQ2Mf0URXQ0NDYx/RRFdDQ0NjH9FEV0NDQ2Mf0URXQ0NDYx/5/8sHUngxeZLiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x216 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "mnist_train = mnist_train.repeat(5).batch(32).prefetch(1)\n",
    "for item in mnist_train:\n",
    "    images = item[\"image\"]\n",
    "    labels = item[\"label\"]\n",
    "    for index in range(5):\n",
    "        plt.subplot(1, 5, index + 1)\n",
    "        image = images[index, ..., 0]\n",
    "        label = labels[index].numpy()\n",
    "        plt.imshow(image, cmap=\"binary\")\n",
    "        plt.title(label)\n",
    "        plt.axis(\"off\")\n",
    "    break # just showing part of the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28, 1)\n",
      "[4 1 0 7 8 1 2 7 1 6 6 4 7 7 3 3 7 9 9 1 0 6 6 9 9 4 8 9 4 7 3 3]\n"
     ]
    }
   ],
   "source": [
    "datasets = tfds.load(name=\"mnist\")\n",
    "mnist_train, mnist_test = datasets[\"train\"], datasets[\"test\"]\n",
    "mnist_train = mnist_train.repeat(5).batch(32)\n",
    "mnist_train = mnist_train.map(lambda items: (items[\"image\"], items[\"label\"]))\n",
    "mnist_train = mnist_train.prefetch(1)\n",
    "for images, labels in mnist_train.take(1):\n",
    "    print(images.shape)\n",
    "    print(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 888us/step - loss: 42.9108 - accuracy: 0.8034\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 684us/step - loss: 24.8643 - accuracy: 0.8701\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 691us/step - loss: 24.3896 - accuracy: 0.8718\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 695us/step - loss: 23.5890 - accuracy: 0.8775\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 717us/step - loss: 22.9626 - accuracy: 0.8798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dd3a8a77f0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "datasets = tfds.load(name=\"mnist\", batch_size=32, as_supervised=True)\n",
    "mnist_train = datasets[\"train\"].repeat().prefetch(1)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28, 1]),\n",
    "    keras.layers.Lambda(lambda images: tf.cast(images, tf.float32)),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(mnist_train, steps_per_epoch=60000 // 32, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
